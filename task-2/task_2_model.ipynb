{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1GX-TGvFDVuL97d5JnLFxhWxfH2Y3eJk2","authorship_tag":"ABX9TyNYoQk1+O+AIHZD617hJEwK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d19403f6ab434ced8cd2c22c6ae9c07d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e266e8ce1bf14681b4b1d6eed407a93b","IPY_MODEL_571d0c9766f9493ea2191ae2366ec84e","IPY_MODEL_206a24008bdb43b2923ba536bc774207"],"layout":"IPY_MODEL_ffdc0e9bba4a45b9859882980f2dac54"}},"e266e8ce1bf14681b4b1d6eed407a93b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b33476a42b024384974fec342bbb8946","placeholder":"​","style":"IPY_MODEL_d9542e5069434662b5f8aaef1c6a6043","value":"100%"}},"571d0c9766f9493ea2191ae2366ec84e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b25844ba9744c82ba3438b1a99ca290","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0c652c8099d466091033a1c2069cffb","value":400}},"206a24008bdb43b2923ba536bc774207":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_628d140161604a318cc5e73d3fa59414","placeholder":"​","style":"IPY_MODEL_50a1ee1b5dd84ca1be52b5f61570f307","value":" 400/400 [22:13&lt;00:00,  3.88s/it]"}},"ffdc0e9bba4a45b9859882980f2dac54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b33476a42b024384974fec342bbb8946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9542e5069434662b5f8aaef1c6a6043":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b25844ba9744c82ba3438b1a99ca290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0c652c8099d466091033a1c2069cffb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"628d140161604a318cc5e73d3fa59414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50a1ee1b5dd84ca1be52b5f61570f307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"grKx3CYIJffo","executionInfo":{"status":"ok","timestamp":1720904003960,"user_tz":240,"elapsed":12850,"user":{"displayName":"MMA Construction","userId":"18335187591541982093"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"36cd90a8-6f39-4952-9bec-bf07f2b8793d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","import re\n","import torch\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n","from tqdm.auto import tqdm\n","\n","\n","class QaModel:\n","    def __init__(self, model_name, num_answers=1):\n","        self.model_name = model_name\n","        self.num_answers = num_answers\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n","        self.model = AutoModelForQuestionAnswering.from_pretrained(self.model_name)\n","        self.qa_pipeline = pipeline(\"question-answering\", model=self.model, tokenizer=self.tokenizer, top_k=self.num_answers)\n","\n","    def predict(self, question, context):\n","        return self.qa_pipeline(question=question, context=context)\n","\n","def get_phrase(row, model_phrase):\n","    question = row.get('postText')[0]\n","    context = ' '.join(row.get('targetParagraphs'))\n","    result = model_phrase.predict(question, context)\n","    print(f\"get_phrase result: {result}\")  # Debugging statement\n","    answer = result['answer'] if 'answer' in result else ''\n","    return [answer]\n","\n","def get_passage(row, model_passage):\n","    question = row.get('postText')[0]\n","    context = ' '.join(row.get('targetParagraphs'))\n","    result = model_passage.predict(question, context)\n","    print(f\"get_passage result: {result}\")  # Debugging statement\n","    answer = result['answer'] if 'answer' in result else ''\n","    candidates = [sentence.strip() for sentence in context.split('.') if answer in sentence]\n","    return [candidates[0] if candidates else '']\n","\n","def get_multi(row, model_multi):\n","    question = row.get('postText')[0]\n","    context = ' '.join(row.get('targetParagraphs'))\n","    current_context = context\n","    results = []\n","    for _ in range(5):\n","        result = model_multi.predict(question, current_context)\n","        print(f\"get_multi result: {result}\")  # Debugging statement\n","        current_result = result['answer'] if 'answer' in result else ''\n","        if not current_result:\n","            break\n","        results.append(current_result)\n","        current_context = re.sub(re.escape(current_result), '', current_context, count=1)\n","    return results\n","\n","def predict(inputs, model_phrase, model_passage, model_multi):\n","    results = []\n","    for row in tqdm(inputs):\n","        if row.get('spoilerType') == 'phrase':\n","            answer = get_phrase(row, model_phrase)\n","        elif row.get('spoilerType') == 'passage':\n","            answer = get_passage(row, model_passage)\n","        elif row.get('spoilerType') == 'multi':\n","            answer = get_multi(row, model_multi)\n","        else:\n","            print(\"Unknown spoiler type\")\n","            answer = [\"\"]\n","\n","        results.append({'id': row['id'], 'spoiler': answer})\n","    return results\n","\n","def run_baseline(input_file, output_file, model_phrase, model_passage, model_multi):\n","    with open(input_file, 'r') as inp, open(output_file, 'w') as out:\n","        inputs = [json.loads(line) for line in inp]\n","        predictions = predict(inputs, model_phrase, model_passage, model_multi)\n","        for prediction in predictions:\n","            out.write(json.dumps(prediction) + '\\n')\n","\n","if __name__ == '__main__':\n","    # Load the data\n","    train_data = pd.read_json('/content/drive/MyDrive/task-1/data/train.jsonl', lines=True)\n","    val_data = pd.read_json('/content/drive/MyDrive/task-1/data/val.jsonl', lines=True)\n","    test_data = pd.read_json('/content/drive/MyDrive/task-1/data/test.jsonl', lines=True)\n","\n","    # Add spoilerType from task 1 predictions to validation and test datasets\n","    task1_predictions = pd.read_csv('/content/drive/MyDrive/task-1/data/prediction_task1.csv')\n","    val_data = val_data.merge(task1_predictions[['id', 'spoilerType']], on='id', how='left')\n","    test_data = test_data.merge(task1_predictions[['id', 'spoilerType']], on='id', how='left')\n","\n","    # Save the merged test data to a new file\n","    test_data.to_json('/content/drive/MyDrive/task-1/data/test-merged.jsonl', lines=True, orient='records')\n","\n","    model_phrase = QaModel(\"deepset/roberta-base-squad2\")\n","    model_passage = QaModel(\"deepset/roberta-base-squad2\")\n","    model_multi = QaModel(\"deepset/roberta-base-squad2\", num_answers=5)\n","\n","    input_file = '/content/drive/MyDrive/task-1/data/test-merged.jsonl'\n","    output_file = '/content/drive/MyDrive/task-2/data/prediction_task2.jsonl'\n","\n","    run_baseline(input_file, output_file, model_phrase=model_phrase, model_passage=model_passage, model_multi=model_multi)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d19403f6ab434ced8cd2c22c6ae9c07d","e266e8ce1bf14681b4b1d6eed407a93b","571d0c9766f9493ea2191ae2366ec84e","206a24008bdb43b2923ba536bc774207","ffdc0e9bba4a45b9859882980f2dac54","b33476a42b024384974fec342bbb8946","d9542e5069434662b5f8aaef1c6a6043","2b25844ba9744c82ba3438b1a99ca290","e0c652c8099d466091033a1c2069cffb","628d140161604a318cc5e73d3fa59414","50a1ee1b5dd84ca1be52b5f61570f307"]},"id":"4ZEtdcPxJkaD","outputId":"a6d83a77-d6a8-4c69-9af0-628a85b3a9ef","executionInfo":{"status":"ok","timestamp":1720911549403,"user_tz":240,"elapsed":1339369,"user":{"displayName":"MMA Construction","userId":"18335187591541982093"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/400 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19403f6ab434ced8cd2c22c6ae9c07d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["get_phrase result: {'score': 0.237760528922081, 'start': 813, 'end': 821, 'answer': 'balloons'}\n","get_multi result: [{'score': 0.03794412687420845, 'start': 3002, 'end': 3043, 'answer': 'selfless people suffer most in workplaces'}, {'score': 0.024626437574625015, 'start': 92, 'end': 142, 'answer': 'putting your needs before those of your colleagues'}, {'score': 0.01864650286734104, 'start': 3002, 'end': 3024, 'answer': 'selfless people suffer'}, {'score': 0.017416542395949364, 'start': 283, 'end': 323, 'answer': 'damages your chance of long-term success'}, {'score': 0.017056172713637352, 'start': 3002, 'end': 3081, 'answer': 'selfless people suffer most in workplaces and find themselves drowning in admin'}]\n","get_passage result: {'score': 0.017889557406306267, 'start': 0, 'end': 65, 'answer': 'Meditating inside a beautiful stock-photo room filled with plants'}\n","get_phrase result: {'score': 0.273841917514801, 'start': 277, 'end': 285, 'answer': 'Braconid'}\n","get_passage result: {'score': 0.0014604085590690374, 'start': 152, 'end': 159, 'answer': 'grating'}\n","get_phrase result: {'score': 0.04039799049496651, 'start': 138, 'end': 157, 'answer': 'John Williams music'}\n","get_multi result: [{'score': 0.19949084520339966, 'start': 2546, 'end': 2580, 'answer': 'anything it takes to get your rest'}, {'score': 0.11217599362134933, 'start': 2546, 'end': 2563, 'answer': 'anything it takes'}, {'score': 0.08645514398813248, 'start': 2543, 'end': 2580, 'answer': 'do anything it takes to get your rest'}, {'score': 0.05099915713071823, 'start': 107, 'end': 138, 'answer': 'Tossing and turning on your bed'}, {'score': 0.04861472174525261, 'start': 2543, 'end': 2563, 'answer': 'do anything it takes'}]\n","get_passage result: {'score': 0.09988722205162048, 'start': 462, 'end': 531, 'answer': \"working dogs should never be pet or played with while they're working\"}\n","get_phrase result: {'score': 0.4086133539676666, 'start': 95, 'end': 116, 'answer': 'Lord Ivar Mountbatten'}\n","get_phrase result: {'score': 0.08882138133049011, 'start': 1502, 'end': 1547, 'answer': 'obsessed with it that they isolate themselves'}\n","get_passage result: {'score': 0.05470702052116394, 'start': 426, 'end': 453, 'answer': 'Who is watching your kids?\"'}\n","get_passage result: {'score': 0.2708269953727722, 'start': 641, 'end': 653, 'answer': 'authenticity'}\n","get_phrase result: {'score': 0.7974903583526611, 'start': 94, 'end': 104, 'answer': 'Celia Cruz'}\n","get_phrase result: {'score': 0.0006180488271638751, 'start': 1018, 'end': 1026, 'answer': 'Mourinho'}\n","get_multi result: [{'score': 0.0055350312031805515, 'start': 6341, 'end': 6423, 'answer': 'Fans of shocking, provocative fiction starring intensely disagreeable characters ―'}, {'score': 0.005039807874709368, 'start': 6341, 'end': 6345, 'answer': 'Fans'}, {'score': 0.003224493470042944, 'start': 6341, 'end': 6421, 'answer': 'Fans of shocking, provocative fiction starring intensely disagreeable characters'}, {'score': 0.001708989148028195, 'start': 6341, 'end': 6435, 'answer': 'Fans of shocking, provocative fiction starring intensely disagreeable characters ― and readers'}, {'score': 0.0011176250409334898, 'start': 6428, 'end': 6468, 'answer': 'readers who don’t mind being grossed out'}]\n","get_passage result: {'score': 0.634727954864502, 'start': 27, 'end': 39, 'answer': '$117 billion'}\n","get_passage result: {'score': 8.51422009873204e-05, 'start': 1290, 'end': 1307, 'answer': \"Chihiro's parents\"}\n","get_phrase result: {'score': 0.028272688388824463, 'start': 655, 'end': 728, 'answer': 'shopping malls have become a kind of replacement for religious structures'}\n","get_multi result: [{'score': 0.2918660342693329, 'start': 929, 'end': 945, 'answer': 'Get an education'}, {'score': 0.12943825125694275, 'start': 926, 'end': 945, 'answer': '1. Get an education'}, {'score': 0.009187807328999043, 'start': 2449, 'end': 2494, 'answer': 'a savings account, a pillowcase, old sneakers'}, {'score': 0.00849613081663847, 'start': 2451, 'end': 2494, 'answer': 'savings account, a pillowcase, old sneakers'}, {'score': 0.005329698324203491, 'start': 929, 'end': 977, 'answer': 'Get an education At least this one will be free.'}]\n","get_passage result: {'score': 0.43363842368125916, 'start': 193, 'end': 201, 'answer': 'New York'}\n","get_phrase result: {'score': 0.29792988300323486, 'start': 34, 'end': 45, 'answer': 'Michael Sam'}\n","get_passage result: {'score': 0.23959708213806152, 'start': 221, 'end': 226, 'answer': 'drunk'}\n","get_passage result: {'score': 0.010722534731030464, 'start': 1279, 'end': 1340, 'answer': 'amazing discounts, which can go up to 90% of the retail value'}\n","get_phrase result: {'score': 0.7207027077674866, 'start': 143, 'end': 149, 'answer': 'yellow'}\n","get_passage result: {'score': 0.28079259395599365, 'start': 33, 'end': 88, 'answer': 'helping to raise awareness about a very important issue'}\n","get_phrase result: {'score': 0.6003342866897583, 'start': 724, 'end': 733, 'answer': 'Comic-Con'}\n","get_multi result: [{'score': 0.022585492581129074, 'start': 301, 'end': 321, 'answer': 'Something was \"off.\"'}, {'score': 0.01290046889334917, 'start': 301, 'end': 319, 'answer': 'Something was \"off'}, {'score': 0.011844823136925697, 'start': 316, 'end': 321, 'answer': 'off.\"'}, {'score': 0.006765571888536215, 'start': 316, 'end': 319, 'answer': 'off'}, {'score': 0.0025656288489699364, 'start': 256, 'end': 321, 'answer': 'She could tell there was sadness in the air. Something was \"off.\"'}]\n","get_passage result: {'score': 0.20644302666187286, 'start': 2043, 'end': 2060, 'answer': 'rising sea levels'}\n","get_passage result: {'score': 0.05982575938105583, 'start': 1340, 'end': 1391, 'answer': 'Trump ran up huge margins with white Florida voters'}\n","get_passage result: {'score': 0.001702115754596889, 'start': 512, 'end': 524, 'answer': 'Y Combinator'}\n","get_phrase result: {'score': 0.13409067690372467, 'start': 493, 'end': 496, 'answer': 'U.S'}\n","get_passage result: {'score': 0.022751856595277786, 'start': 327, 'end': 342, 'answer': 'hilarious video'}\n","get_passage result: {'score': 0.0001606772857485339, 'start': 3736, 'end': 3774, 'answer': 'they were much lower than they are now'}\n","get_passage result: {'score': 0.15327824652194977, 'start': 1469, 'end': 1523, 'answer': 'the NES Classic Edition is not available for pre-order'}\n","get_phrase result: {'score': 0.0004957834025844932, 'start': 1662, 'end': 1725, 'answer': \"Students] can't shop around and find the most affordable option\"}\n","get_phrase result: {'score': 1.4050542631593999e-06, 'start': 1141, 'end': 1187, 'answer': 'belts out a few of his favorite Broadway tunes'}\n","get_passage result: {'score': 0.004043889231979847, 'start': 58, 'end': 66, 'answer': 'Laziness'}\n","get_multi result: [{'score': 0.3287962079048157, 'start': 116, 'end': 122, 'answer': 'Austin'}, {'score': 0.13726158440113068, 'start': 116, 'end': 129, 'answer': 'Austin, Texas'}, {'score': 0.06480640172958374, 'start': 2880, 'end': 2886, 'answer': 'Austin'}, {'score': 0.039871178567409515, 'start': 1086, 'end': 1092, 'answer': 'Austin'}, {'score': 0.012829270213842392, 'start': 2511, 'end': 2517, 'answer': 'Austin'}]\n","get_passage result: {'score': 0.14118516445159912, 'start': 4694, 'end': 4738, 'answer': 'because he got the disease when he was young'}\n","get_passage result: {'score': 0.02110615186393261, 'start': 1103, 'end': 1107, 'answer': 'blue'}\n","get_phrase result: {'score': 0.12713773548603058, 'start': 2812, 'end': 2816, 'answer': 'blue'}\n","get_passage result: {'score': 0.05962340161204338, 'start': 80, 'end': 127, 'answer': \"there is fresh beer on the red planet's surface\"}\n","get_phrase result: {'score': 0.05647725984454155, 'start': 16, 'end': 26, 'answer': 'Parenthood'}\n","get_passage result: {'score': 0.12641401588916779, 'start': 1972, 'end': 1990, 'answer': 'those subway vents'}\n","get_passage result: {'score': 0.25647401809692383, 'start': 1709, 'end': 1719, 'answer': 'wood plank'}\n","get_phrase result: {'score': 0.06982126832008362, 'start': 16, 'end': 28, 'answer': 'Jason Aldean'}\n","get_passage result: {'score': 4.458255261852173e-06, 'start': 1596, 'end': 1608, 'answer': 'Harry pocket'}\n","get_multi result: [{'score': 0.1906692534685135, 'start': 5257, 'end': 5269, 'answer': '1,448.7 days'}, {'score': 0.04900031536817551, 'start': 5344, 'end': 5353, 'answer': '207 weeks'}, {'score': 0.032028164714574814, 'start': 5344, 'end': 5380, 'answer': '207 weeks, or just shy of four years'}, {'score': 0.008509679697453976, 'start': 5259, 'end': 5269, 'answer': '448.7 days'}, {'score': 0.007273151073604822, 'start': 5257, 'end': 5264, 'answer': '1,448.7'}]\n","get_passage result: {'score': 0.00013501210196409374, 'start': 2100, 'end': 2142, 'answer': 'Eminem, or anyone like that before kickoff'}\n","get_passage result: {'score': 0.12022726982831955, 'start': 1186, 'end': 1213, 'answer': 'I can afford more than that'}\n","get_phrase result: {'score': 0.003928224556148052, 'start': 1216, 'end': 1258, 'answer': 'how he would be viewed by fans of the show'}\n","get_passage result: {'score': 3.9461327105527744e-05, 'start': 3845, 'end': 3855, 'answer': 'developers'}\n","get_passage result: {'score': 0.03541808947920799, 'start': 559, 'end': 588, 'answer': 'lack of an audience in Russia'}\n","get_multi result: [{'score': 0.09038940817117691, 'start': 4870, 'end': 4892, 'answer': 'high blood cholesterol'}, {'score': 0.0864921435713768, 'start': 4870, 'end': 4892, 'answer': 'high blood cholesterol'}, {'score': 0.05372542887926102, 'start': 4856, 'end': 4892, 'answer': 'those who had high blood cholesterol'}, {'score': 0.047495946288108826, 'start': 4856, 'end': 4892, 'answer': 'those who had high blood cholesterol'}, {'score': 0.02660319022834301, 'start': 4870, 'end': 4906, 'answer': 'high blood cholesterol to start with'}]\n","get_phrase result: {'score': 0.854967474937439, 'start': 52, 'end': 64, 'answer': 'Pennsylvania'}\n","get_passage result: {'score': 0.0014112560311332345, 'start': 1620, 'end': 1624, 'answer': 'food'}\n","get_phrase result: {'score': 0.043743424117565155, 'start': 3701, 'end': 3724, 'answer': 'widowed or divorced men'}\n","get_phrase result: {'score': 0.005285616964101791, 'start': 250, 'end': 282, 'answer': 'get ready to feel warm and fuzzy'}\n","get_passage result: {'score': 1.451420189368946e-06, 'start': 185, 'end': 189, 'answer': 'Kili'}\n","get_phrase result: {'score': 0.1026562973856926, 'start': 15, 'end': 26, 'answer': 'Miley Cyrus'}\n","get_passage result: {'score': 0.0003507835790514946, 'start': 213, 'end': 277, 'answer': 'London teacher this weekend had pupils reacting quite oppositely'}\n","get_passage result: {'score': 0.007710477337241173, 'start': 0, 'end': 5, 'answer': 'Poké'}\n","get_passage result: {'score': 0.2413465976715088, 'start': 2173, 'end': 2176, 'answer': 'men'}\n","get_phrase result: {'score': 0.00202437792904675, 'start': 589, 'end': 610, 'answer': 'I don’t have a closet'}\n","get_passage result: {'score': 0.205937922000885, 'start': 590, 'end': 642, 'answer': 'If Mr. Trump can’t reunify Republican-leaning voters'}\n","get_passage result: {'score': 0.2735932469367981, 'start': 1032, 'end': 1083, 'answer': 'post pictures of your boarding pass on social media'}\n","get_passage result: {'score': 0.027900943532586098, 'start': 1534, 'end': 1551, 'answer': '1209 North Orange'}\n","get_passage result: {'score': 0.5526566505432129, 'start': 317, 'end': 327, 'answer': 'Kevin Hart'}\n","get_phrase result: {'score': 0.0004939568461850286, 'start': 1477, 'end': 1491, 'answer': '$79 last March'}\n","get_phrase result: {'score': 0.5905234813690186, 'start': 2612, 'end': 2629, 'answer': '$12,500 per month'}\n","get_phrase result: {'score': 0.2957761585712433, 'start': 1711, 'end': 1743, 'answer': 'New Home Button, New Limitations'}\n","get_phrase result: {'score': 0.000647054344881326, 'start': 5818, 'end': 5823, 'answer': 'Anita'}\n","get_multi result: [{'score': 0.00786307081580162, 'start': 337, 'end': 369, 'answer': 'Doors open based on who you know'}, {'score': 0.0007560457452200353, 'start': 1763, 'end': 1778, 'answer': 'business casual'}, {'score': 0.0004872242279816419, 'start': 298, 'end': 369, 'answer': 'much of that guidance still resonates. Doors open based on who you know'}, {'score': 0.00027648636023513973, 'start': 2654, 'end': 2662, 'answer': 'humility'}, {'score': 0.00024564340128563344, 'start': 233, 'end': 258, 'answer': 'my father and a professor'}]\n","get_multi result: [{'score': 7.073205051710829e-05, 'start': 3400, 'end': 3415, 'answer': 'Vatican Museums'}, {'score': 4.926104156766087e-05, 'start': 5785, 'end': 5809, 'answer': 'Victoria & Albert Museum'}, {'score': 3.43386891472619e-05, 'start': 5781, 'end': 5809, 'answer': 'The Victoria & Albert Museum'}, {'score': 3.0679511837661266e-05, 'start': 138, 'end': 161, 'answer': '1. Museum of Modern Art'}, {'score': 2.191889325331431e-05, 'start': 141, 'end': 161, 'answer': 'Museum of Modern Art'}]\n","get_passage result: {'score': 0.03504900261759758, 'start': 322, 'end': 333, 'answer': 'A dietitian'}\n","get_phrase result: {'score': 0.001739852479659021, 'start': 4861, 'end': 4876, 'answer': 'Marching Powder'}\n","get_passage result: {'score': 0.013000622391700745, 'start': 4503, 'end': 4533, 'answer': 'surfaces coated in methane ice'}\n","get_multi result: [{'score': 0.059503521770238876, 'start': 439, 'end': 444, 'answer': 'Tokyo'}, {'score': 0.00929758045822382, 'start': 962, 'end': 967, 'answer': 'Tokyo'}, {'score': 0.001638987334445119, 'start': 962, 'end': 994, 'answer': 'Tokyo: As mentioned above, Tokyo'}, {'score': 0.0010803689947351813, 'start': 962, 'end': 968, 'answer': 'Tokyo:'}, {'score': 0.0010290127247571945, 'start': 1605, 'end': 1612, 'answer': 'Chicago'}]\n","get_phrase result: {'score': 0.08306630700826645, 'start': 228, 'end': 236, 'answer': 'Snapchat'}\n","get_phrase result: {'score': 0.9521483182907104, 'start': 307, 'end': 318, 'answer': 'Mexico City'}\n","get_passage result: {'score': 0.2550138831138611, 'start': 202, 'end': 210, 'answer': 'MS Dhoni'}\n","get_passage result: {'score': 0.002620812738314271, 'start': 490, 'end': 517, 'answer': 'her metabolism slowing down'}\n","get_phrase result: {'score': 0.03425272926688194, 'start': 1261, 'end': 1271, 'answer': 'Don Draper'}\n","get_passage result: {'score': 0.003427335759624839, 'start': 1116, 'end': 1128, 'answer': 'Secrets Week'}\n","get_passage result: {'score': 0.03816067427396774, 'start': 5749, 'end': 5775, 'answer': 'use the product before bed'}\n","get_passage result: {'score': 0.005567542742937803, 'start': 427, 'end': 472, 'answer': 'there are tons of benefits to metcon workouts'}\n","get_phrase result: {'score': 0.96956467628479, 'start': 244, 'end': 254, 'answer': 'Katy Perry'}\n","get_passage result: {'score': 0.5664356350898743, 'start': 19, 'end': 34, 'answer': 'The Netherlands'}\n","get_passage result: {'score': 0.004734749905765057, 'start': 596, 'end': 602, 'answer': 'Tetteh'}\n","get_passage result: {'score': 8.021294343052432e-05, 'start': 1196, 'end': 1222, 'answer': 'I absolutely rejected it.\"'}\n","get_passage result: {'score': 0.26420289278030396, 'start': 1500, 'end': 1518, 'answer': 'free doormat photo'}\n","get_multi result: [{'score': 0.01546943187713623, 'start': 2849, 'end': 2893, 'answer': \"there isn't anything we're not dousing it on\"}, {'score': 0.004900977481156588, 'start': 1900, 'end': 1924, 'answer': '5. I CAN NEVER ESCAPE IT'}, {'score': 0.0036056789103895426, 'start': 3176, 'end': 3215, 'answer': 'Mustard (maybe sauerkraut, too) on dogs'}, {'score': 0.0029731967952102423, 'start': 3176, 'end': 3183, 'answer': 'Mustard'}, {'score': 0.0028053985442966223, 'start': 2849, 'end': 2890, 'answer': \"there isn't anything we're not dousing it\"}]\n","get_multi result: [{'score': 0.03498312458395958, 'start': 1701, 'end': 1709, 'answer': 'Kat Cole'}, {'score': 0.0011078966781497002, 'start': 1934, 'end': 1942, 'answer': 'waitress'}, {'score': 0.0004643576976377517, 'start': 1701, 'end': 1735, 'answer': 'Kat Cole Position: CEO of Cinnabon'}, {'score': 0.00042148822103627026, 'start': 1932, 'end': 1942, 'answer': 'a waitress'}, {'score': 0.00023920157400425524, 'start': 1705, 'end': 1709, 'answer': 'Cole'}]\n","get_phrase result: {'score': 0.04055825248360634, 'start': 2497, 'end': 2543, 'answer': 'receipts for pencils he purchased in the 1950s'}\n","get_passage result: {'score': 0.7298142313957214, 'start': 200, 'end': 233, 'answer': 'wants to make America great again'}\n","get_phrase result: {'score': 0.013840839266777039, 'start': 97, 'end': 110, 'answer': 'Peter Pilotto'}\n","get_phrase result: {'score': 0.4628433287143707, 'start': 54, 'end': 83, 'answer': 'adoption of modern lifestyles'}\n","get_passage result: {'score': 0.10235203057527542, 'start': 150, 'end': 163, 'answer': 'vocal opinion'}\n","get_passage result: {'score': 0.06345438957214355, 'start': 361, 'end': 383, 'answer': 'It is an expensive bet'}\n","get_passage result: {'score': 0.04251165688037872, 'start': 1201, 'end': 1243, 'answer': 'He is utterly indifferent to its existence'}\n","get_multi result: [{'score': 0.02028663456439972, 'start': 46, 'end': 52, 'answer': 'Asians'}, {'score': 0.004669600632041693, 'start': 46, 'end': 92, 'answer': 'Asians are becoming free independent travelers'}, {'score': 0.003914190456271172, 'start': 41, 'end': 52, 'answer': 'more Asians'}, {'score': 0.002155799651518464, 'start': 3394, 'end': 3432, 'answer': 'snow mobile safaris and winter fishing'}, {'score': 0.000900972809176892, 'start': 41, 'end': 92, 'answer': 'more Asians are becoming free independent travelers'}]\n","get_phrase result: {'score': 1.5515480527028558e-06, 'start': 2865, 'end': 2921, 'answer': 'latest installments of \"Gears of War\" and \"Battlefield,\"'}\n","get_phrase result: {'score': 0.004921795800328255, 'start': 63, 'end': 142, 'answer': 'Thai people spend the majority of their waking hours being completely sedentary'}\n","get_passage result: {'score': 0.023185456171631813, 'start': 122, 'end': 151, 'answer': 'online multiplayer unplayable'}\n","get_passage result: {'score': 0.0684475526213646, 'start': 443, 'end': 468, 'answer': 'raw apple and raw lettuce'}\n","get_passage result: {'score': 0.0003351608174853027, 'start': 1018, 'end': 1022, 'answer': 'pack'}\n","get_phrase result: {'score': 0.07799535244703293, 'start': 43, 'end': 48, 'answer': 'pasta'}\n","get_passage result: {'score': 0.0006081097526475787, 'start': 204, 'end': 225, 'answer': 'running for the hills'}\n","get_passage result: {'score': 1.3305959782883292e-06, 'start': 1752, 'end': 1753, 'answer': '\\u200b'}\n","get_passage result: {'score': 0.0009368809987790883, 'start': 315, 'end': 385, 'answer': 'Authorities are yet to begin an investigation in the cause of the fire'}\n","get_passage result: {'score': 0.0011115262750536203, 'start': 10711, 'end': 10768, 'answer': 'Shoving a square peg of charity into a round hole of need'}\n","get_passage result: {'score': 0.032323699444532394, 'start': 574, 'end': 626, 'answer': 'the police get smarter, so the criminals get nastier'}\n","get_passage result: {'score': 0.011142945848405361, 'start': 323, 'end': 376, 'answer': 'It looks like he’s trying to cosplay as an Angry Bird'}\n","get_phrase result: {'score': 0.13580630719661713, 'start': 2505, 'end': 2519, 'answer': 'the title page'}\n","get_phrase result: {'score': 0.14180277287960052, 'start': 0, 'end': 17, 'answer': 'Shamus Beaglehole'}\n","get_passage result: {'score': 0.053322892636060715, 'start': 98, 'end': 105, 'answer': 'privacy'}\n","get_phrase result: {'score': 0.07893922179937363, 'start': 325, 'end': 337, 'answer': 'Wolverampton'}\n","get_phrase result: {'score': 0.000842422479763627, 'start': 163, 'end': 174, 'answer': 'Mitch Fritz'}\n","get_passage result: {'score': 0.03148825094103813, 'start': 898, 'end': 939, 'answer': 'It’s the preeminent blockbuster blueprint'}\n","get_phrase result: {'score': 0.37749871611595154, 'start': 683, 'end': 695, 'answer': 'Ruby Tuesday'}\n","get_passage result: {'score': 0.003548044478520751, 'start': 1968, 'end': 2037, 'answer': 'The world economy still feels shaky, especially after the Brexit vote'}\n","get_phrase result: {'score': 0.004827358294278383, 'start': 220, 'end': 233, 'answer': '29-cent towel'}\n","get_phrase result: {'score': 0.08991555869579315, 'start': 1229, 'end': 1236, 'answer': 'J. Crew'}\n","get_passage result: {'score': 0.014022051356732845, 'start': 0, 'end': 73, 'answer': 'One former union boss has a bold idea on how to ensure economic stability'}\n","get_passage result: {'score': 0.006338486447930336, 'start': 454, 'end': 498, 'answer': 'the main character almost never has a mother'}\n","get_passage result: {'score': 8.345124660991132e-05, 'start': 43, 'end': 55, 'answer': 'Donald Trump'}\n","get_passage result: {'score': 0.0212343018501997, 'start': 720, 'end': 727, 'answer': 'a watch'}\n","get_passage result: {'score': 0.00032405051751993597, 'start': 410, 'end': 427, 'answer': 'unbearably smelly'}\n","get_phrase result: {'score': 0.003473941469565034, 'start': 63, 'end': 70, 'answer': 'Destiny'}\n","get_passage result: {'score': 0.11209425330162048, 'start': 1179, 'end': 1221, 'answer': 'you won’t be seeing that with the Xbox One'}\n","get_phrase result: {'score': 0.0030006638262420893, 'start': 85, 'end': 146, 'answer': 'The warehouse retailer’s 16-year partnership with has expired'}\n","get_phrase result: {'score': 0.3778645098209381, 'start': 194, 'end': 207, 'answer': 'online gaming'}\n","get_passage result: {'score': 0.015891587361693382, 'start': 857, 'end': 905, 'answer': 'Howard says as he walks the streets of Hong Kong'}\n","get_passage result: {'score': 0.06553688645362854, 'start': 534, 'end': 599, 'answer': 'fewer than half of all participants correctly identified the logo'}\n","get_phrase result: {'score': 0.0283501073718071, 'start': 17, 'end': 28, 'answer': 'Ammon Bundy'}\n","get_passage result: {'score': 0.7412930727005005, 'start': 864, 'end': 873, 'answer': 'frostbite'}\n","get_passage result: {'score': 0.020471803843975067, 'start': 2427, 'end': 2444, 'answer': 'sign the petition'}\n","get_phrase result: {'score': 0.0021379387471824884, 'start': 2, 'end': 11, 'answer': 'snowshoer'}\n","get_multi result: [{'score': 0.11214622855186462, 'start': 372, 'end': 411, 'answer': 'used condoms being discarded under beds'}, {'score': 0.03311893343925476, 'start': 372, 'end': 384, 'answer': 'used condoms'}, {'score': 0.02564862370491028, 'start': 372, 'end': 441, 'answer': 'used condoms being discarded under beds and women flashing the porter'}, {'score': 0.01644977182149887, 'start': 416, 'end': 465, 'answer': 'women flashing the porter instead of giving a tip'}, {'score': 0.012134239077568054, 'start': 372, 'end': 400, 'answer': 'used condoms being discarded'}]\n","get_passage result: {'score': 0.008656860329210758, 'start': 454, 'end': 472, 'answer': 'To avoid the tiffs'}\n","get_phrase result: {'score': 0.11672472208738327, 'start': 116, 'end': 127, 'answer': 'José José'}\n","get_passage result: {'score': 0.04769524559378624, 'start': 2824, 'end': 2832, 'answer': 'billions'}\n","get_phrase result: {'score': 0.0022302742581814528, 'start': 197, 'end': 235, 'answer': 'Here is the year that was in good news'}\n","get_passage result: {'score': 0.008360103704035282, 'start': 3038, 'end': 3084, 'answer': 'assuming we still exist that far in the future'}\n","get_passage result: {'score': 0.009631840512156487, 'start': 22, 'end': 44, 'answer': '24-week pregnant woman'}\n","get_passage result: {'score': 0.011888948269188404, 'start': 631, 'end': 658, 'answer': 'it’s probably time to panic'}\n","get_passage result: {'score': 0.04591239243745804, 'start': 1747, 'end': 1782, 'answer': 'remains intact even after its death'}\n","get_phrase result: {'score': 0.01024257019162178, 'start': 471, 'end': 551, 'answer': 'people pour water over the lingam with vessels made from copper of various sizes'}\n","get_passage result: {'score': 0.12153974920511246, 'start': 596, 'end': 620, 'answer': 'she had a house close-by'}\n","get_phrase result: {'score': 0.12503084540367126, 'start': 212, 'end': 219, 'answer': 'June 17'}\n","get_passage result: {'score': 0.07534323632717133, 'start': 378, 'end': 404, 'answer': \"he's not anti-Harry Potter\"}\n","get_phrase result: {'score': 0.7474138736724854, 'start': 93, 'end': 101, 'answer': 'The Rock'}\n","get_phrase result: {'score': 0.37226560711860657, 'start': 0, 'end': 14, 'answer': 'Jackson Vroman'}\n","get_multi result: [{'score': 0.5613710284233093, 'start': 290, 'end': 295, 'answer': 'seven'}, {'score': 0.13343897461891174, 'start': 290, 'end': 317, 'answer': 'seven conservative classics'}, {'score': 0.05615506321191788, 'start': 290, 'end': 362, 'answer': 'seven conservative classics that should be on every American’s bookshelf'}, {'score': 0.007977011613547802, 'start': 296, 'end': 317, 'answer': 'conservative classics'}, {'score': 0.004935495089739561, 'start': 274, 'end': 295, 'answer': 'Here, then, are seven'}]\n","get_passage result: {'score': 0.0022501822095364332, 'start': 82, 'end': 106, 'answer': 'prototype imaging system'}\n","get_passage result: {'score': 0.06264845281839371, 'start': 1479, 'end': 1499, 'answer': 'She\\'s not worth it.\"'}\n","get_multi result: [{'score': 0.2199755609035492, 'start': 4847, 'end': 4923, 'answer': 'nuts contain melatonin as well as essential minerals like magnesium and zinc'}, {'score': 0.12134671211242676, 'start': 4847, 'end': 4869, 'answer': 'nuts contain melatonin'}, {'score': 0.05383468419313431, 'start': 4847, 'end': 4851, 'answer': 'nuts'}, {'score': 0.04714549332857132, 'start': 4705, 'end': 4709, 'answer': 'Nuts'}, {'score': 0.04655751585960388, 'start': 4847, 'end': 4899, 'answer': 'nuts contain melatonin as well as essential minerals'}]\n","get_phrase result: {'score': 0.0001651156781008467, 'start': 58, 'end': 71, 'answer': 'Penn Jillette'}\n","get_multi result: [{'score': 0.01719120889902115, 'start': 143, 'end': 159, 'answer': 'top beauty gurus'}, {'score': 0.005420166067779064, 'start': 139, 'end': 159, 'answer': 'the top beauty gurus'}, {'score': 0.004168189596384764, 'start': 147, 'end': 159, 'answer': 'beauty gurus'}, {'score': 0.0034026606008410454, 'start': 143, 'end': 201, 'answer': 'top beauty gurus in the business, applying your foundation'}, {'score': 0.0031150130089372396, 'start': 191, 'end': 224, 'answer': 'foundation, blusher and concealer'}]\n","get_passage result: {'score': 0.4309816062450409, 'start': 30, 'end': 58, 'answer': 'Taran Killam and Jay Pharoah'}\n","get_phrase result: {'score': 0.8895003199577332, 'start': 642, 'end': 647, 'answer': 'Idaho'}\n","get_passage result: {'score': 0.00012018893175991252, 'start': 2799, 'end': 2842, 'answer': 'The term \"literary fiction\" seems arbitrary'}\n","get_passage result: {'score': 0.02760438434779644, 'start': 1535, 'end': 1561, 'answer': 'admit that she’s an addict'}\n","get_passage result: {'score': 0.3326837420463562, 'start': 320, 'end': 327, 'answer': 'low IQs'}\n","get_phrase result: {'score': 0.1830829232931137, 'start': 249, 'end': 251, 'answer': '77'}\n","get_passage result: {'score': 0.02736494690179825, 'start': 2200, 'end': 2213, 'answer': 'when we sleep'}\n","get_passage result: {'score': 0.20749975740909576, 'start': 1877, 'end': 1929, 'answer': 'throw any Olympic predictions seriously out of whack'}\n","get_passage result: {'score': 0.06092057377099991, 'start': 156, 'end': 161, 'answer': 'penis'}\n","get_multi result: [{'score': 0.02240024134516716, 'start': 565, 'end': 585, 'answer': \"Don't touch her bump\"}, {'score': 0.015784291550517082, 'start': 389, 'end': 398, 'answer': 'Zita West'}, {'score': 0.00446607219055295, 'start': 565, 'end': 618, 'answer': \"Don't touch her bump Invading people's personal space\"}, {'score': 0.004242982715368271, 'start': 4994, 'end': 5033, 'answer': \"Do tell her she's going to be just fine\"}, {'score': 0.003108727280050516, 'start': 562, 'end': 585, 'answer': \"1. Don't touch her bump\"}]\n","get_phrase result: {'score': 0.002411654219031334, 'start': 1525, 'end': 1545, 'answer': 'affordable childcare'}\n","get_passage result: {'score': 0.0003778628015425056, 'start': 599, 'end': 622, 'answer': 'shockingly large amount'}\n","get_passage result: {'score': 0.33659493923187256, 'start': 0, 'end': 70, 'answer': 'Laws that maintain the legal drinking age at 21 save lives on the road'}\n","get_phrase result: {'score': 0.02827325463294983, 'start': 669, 'end': 675, 'answer': 'Oregon'}\n","get_phrase result: {'score': 9.329593808615755e-08, 'start': 620, 'end': 628, 'answer': 'who knew'}\n","get_phrase result: {'score': 0.01840600185096264, 'start': 274, 'end': 296, 'answer': 'ambassadorial capacity'}\n","get_phrase result: {'score': 9.938345465343446e-05, 'start': 1, 'end': 19, 'answer': 'Dumb and Dumber To'}\n","get_passage result: {'score': 0.02736194059252739, 'start': 1083, 'end': 1164, 'answer': 'never taking things for granted and helping spread awareness of children’s cancer'}\n","get_passage result: {'score': 0.021601742133498192, 'start': 1591, 'end': 1615, 'answer': 'fell an average of 13.7%'}\n","get_phrase result: {'score': 0.001322824158705771, 'start': 8191, 'end': 8197, 'answer': 'squash'}\n","get_phrase result: {'score': 0.0031666529830545187, 'start': 352, 'end': 405, 'answer': 'sitting on a couch, reading newspaper and sipping tea'}\n","get_phrase result: {'score': 0.7292564511299133, 'start': 585, 'end': 603, 'answer': 'strawberry rhubarb'}\n","get_phrase result: {'score': 0.2477235645055771, 'start': 416, 'end': 425, 'answer': 'paper bag'}\n","get_passage result: {'score': 0.00016022162162698805, 'start': 273, 'end': 280, 'answer': 'boiling'}\n","get_phrase result: {'score': 0.04235881194472313, 'start': 1288, 'end': 1299, 'answer': 'moisturizer'}\n","get_phrase result: {'score': 0.4950467050075531, 'start': 522, 'end': 533, 'answer': 'Jimmy Smits'}\n","get_passage result: {'score': 0.10098221898078918, 'start': 1330, 'end': 1378, 'answer': 'unless Linux rectifies its performance disparity'}\n","get_passage result: {'score': 0.19098766148090363, 'start': 9815, 'end': 9820, 'answer': 'never'}\n","get_passage result: {'score': 0.0027511257212609053, 'start': 1435, 'end': 1474, 'answer': 'Justin, you’re still a bag of dick tips'}\n","get_multi result: [{'score': 1.1442577488196548e-05, 'start': 2653, 'end': 2693, 'answer': 'this game still hasn’t made it to market'}, {'score': 6.460196345869917e-06, 'start': 2663, 'end': 2693, 'answer': 'still hasn’t made it to market'}, {'score': 6.196662980073597e-06, 'start': 2669, 'end': 2693, 'answer': 'hasn’t made it to market'}, {'score': 4.127951797272544e-06, 'start': 2424, 'end': 2443, 'answer': '3. Final Fantasy XV'}, {'score': 3.2765415198809933e-06, 'start': 2427, 'end': 2443, 'answer': 'Final Fantasy XV'}]\n","get_passage result: {'score': 0.03760271519422531, 'start': 453, 'end': 468, 'answer': 'on the shoulder'}\n","get_passage result: {'score': 0.39119791984558105, 'start': 99, 'end': 130, 'answer': 'played outside with her friends'}\n","get_phrase result: {'score': 0.002843816066160798, 'start': 191, 'end': 201, 'answer': 'Laura Bush'}\n","get_phrase result: {'score': 0.00039500484126619995, 'start': 1383, 'end': 1388, 'answer': 'Brain'}\n","get_passage result: {'score': 0.001502331579104066, 'start': 1081, 'end': 1086, 'answer': 'Adele'}\n","get_passage result: {'score': 0.03750859946012497, 'start': 459, 'end': 492, 'answer': 'JT managed to swat away the woman'}\n","get_passage result: {'score': 0.3236255943775177, 'start': 70, 'end': 99, 'answer': 'the extra pinch to the pocket'}\n","get_multi result: [{'score': 0.053100861608982086, 'start': 3607, 'end': 3615, 'answer': 'Colorado'}, {'score': 0.040328290313482285, 'start': 497, 'end': 505, 'answer': 'Colorado'}, {'score': 0.013271954841911793, 'start': 3816, 'end': 3822, 'answer': 'Denver'}, {'score': 0.013243605382740498, 'start': 49, 'end': 57, 'answer': 'Colorado'}, {'score': 0.01100088655948639, 'start': 393, 'end': 401, 'answer': 'Colorado'}]\n","get_passage result: {'score': 0.013139205984771252, 'start': 170, 'end': 177, 'answer': '234,000'}\n","get_passage result: {'score': 0.16541726887226105, 'start': 304, 'end': 374, 'answer': \"It simply couldn't make enough toys to satiate demand in North America\"}\n","get_phrase result: {'score': 0.0023792788852006197, 'start': 1574, 'end': 1597, 'answer': 'return to the franchise'}\n","get_passage result: {'score': 0.002590558724477887, 'start': 71, 'end': 89, 'answer': 'bio-metric details'}\n","get_multi result: [{'score': 0.14882336556911469, 'start': 1980, 'end': 2036, 'answer': 'the new season will have a heavy James Cameron influence'}, {'score': 0.024159936234354973, 'start': 1984, 'end': 2036, 'answer': 'new season will have a heavy James Cameron influence'}, {'score': 0.02274681255221367, 'start': 2013, 'end': 2036, 'answer': 'James Cameron influence'}, {'score': 0.021745435893535614, 'start': 2007, 'end': 2036, 'answer': 'heavy James Cameron influence'}, {'score': 0.019519180059432983, 'start': 2005, 'end': 2036, 'answer': 'a heavy James Cameron influence'}]\n","get_phrase result: {'score': 0.011146089062094688, 'start': 1183, 'end': 1201, 'answer': 'about 10 years ago'}\n","get_passage result: {'score': 0.10667154937982559, 'start': 1165, 'end': 1189, 'answer': 'load up on lotto tickets'}\n","get_phrase result: {'score': 0.002829489065334201, 'start': 1150, 'end': 1160, 'answer': 'slick move'}\n","get_passage result: {'score': 0.00891995057463646, 'start': 210, 'end': 225, 'answer': 'Tulsiram Manere'}\n","get_passage result: {'score': 0.0162377767264843, 'start': 155, 'end': 169, 'answer': 'Ailish Sheehan'}\n","get_passage result: {'score': 0.029665537178516388, 'start': 1010, 'end': 1110, 'answer': 'participants feel more confident and motivated to achieve the same satisfactory feeling the next day'}\n","get_phrase result: {'score': 0.3281794488430023, 'start': 44, 'end': 51, 'answer': 'Chicago'}\n","get_phrase result: {'score': 0.0036963606253266335, 'start': 236, 'end': 268, 'answer': 'being a sex object is empowering'}\n","get_passage result: {'score': 0.0012960381573066115, 'start': 2336, 'end': 2370, 'answer': \"there's a real concern over ethics\"}\n","get_phrase result: {'score': 0.6861680150032043, 'start': 239, 'end': 249, 'answer': 'french fry'}\n","get_passage result: {'score': 0.016543464735150337, 'start': 2068, 'end': 2075, 'answer': 'rituals'}\n","get_passage result: {'score': 0.23721450567245483, 'start': 120, 'end': 166, 'answer': 'she got distracted by her own ‘erotic thoughts'}\n","get_passage result: {'score': 0.016754264011979103, 'start': 914, 'end': 937, 'answer': \"don't touch that button\"}\n","get_passage result: {'score': 0.23449914157390594, 'start': 3950, 'end': 3969, 'answer': '3 is greater than 2'}\n","get_passage result: {'score': 0.0009396172827109694, 'start': 128, 'end': 133, 'answer': 'Eatsa'}\n","get_phrase result: {'score': 0.008807424455881119, 'start': 2386, 'end': 2401, 'answer': '$10,527,843,932'}\n","get_passage result: {'score': 0.001517768600024283, 'start': 98, 'end': 112, 'answer': '1-999-367-3767'}\n","get_phrase result: {'score': 0.7903422117233276, 'start': 128, 'end': 136, 'answer': 'colleges'}\n","get_phrase result: {'score': 0.2689262628555298, 'start': 606, 'end': 624, 'answer': 'devoutly religious'}\n","get_passage result: {'score': 0.44187235832214355, 'start': 981, 'end': 990, 'answer': 'divorcing'}\n","get_passage result: {'score': 0.06218063458800316, 'start': 4021, 'end': 4034, 'answer': 'stray animals'}\n","get_phrase result: {'score': 5.237328150542453e-05, 'start': 30, 'end': 44, 'answer': 'North Carolina'}\n","get_passage result: {'score': 0.019097506999969482, 'start': 62, 'end': 72, 'answer': 'The father'}\n","get_phrase result: {'score': 0.16391992568969727, 'start': 823, 'end': 837, 'answer': 'almost $37,000'}\n","get_passage result: {'score': 0.033385924994945526, 'start': 623, 'end': 633, 'answer': 'I Miss You'}\n","get_phrase result: {'score': 0.002814012812450528, 'start': 395, 'end': 397, 'answer': '32'}\n","get_phrase result: {'score': 0.0630832090973854, 'start': 963, 'end': 966, 'answer': 'Ana'}\n","get_passage result: {'score': 0.0007979230722412467, 'start': 1550, 'end': 1557, 'answer': 'Barkley'}\n","get_passage result: {'score': 0.01974719949066639, 'start': 103, 'end': 163, 'answer': 'the local coroner’s office just did their own act of support'}\n","get_phrase result: {'score': 0.11935356259346008, 'start': 298, 'end': 303, 'answer': 'pears'}\n","get_phrase result: {'score': 0.3180466592311859, 'start': 25, 'end': 37, 'answer': 'Blake McIver'}\n","get_phrase result: {'score': 5.8120738685829565e-05, 'start': 266, 'end': 284, 'answer': 'state legislatures'}\n","get_phrase result: {'score': 0.011128424666821957, 'start': 1622, 'end': 1624, 'answer': 'Li'}\n","get_multi result: [{'score': 0.00347935501486063, 'start': 402, 'end': 410, 'answer': 'twerking'}, {'score': 0.0010555338812991977, 'start': 630, 'end': 635, 'answer': 'Drake'}, {'score': 0.0008935660007409751, 'start': 499, 'end': 551, 'answer': 'swinging around on a wrecking ball, naked and crying'}, {'score': 0.0008380943327210844, 'start': 342, 'end': 410, 'answer': \"Miley likely ranked the highest on Google's list because of twerking\"}, {'score': 0.0007543875253759325, 'start': 630, 'end': 641, 'answer': 'Drake Drake'}]\n","get_passage result: {'score': 0.0038839918561279774, 'start': 545, 'end': 546, 'answer': '😂'}\n","get_phrase result: {'score': 0.00043708551675081253, 'start': 116, 'end': 130, 'answer': 'Caitlyn Cannon'}\n","get_passage result: {'score': 0.016913175582885742, 'start': 238, 'end': 247, 'answer': 'belly rub'}\n","get_phrase result: {'score': 0.00042385878623463213, 'start': 150, 'end': 168, 'answer': 'Inside Amy Schumer'}\n","get_passage result: {'score': 0.02677895501255989, 'start': 1302, 'end': 1348, 'answer': 'a triangle with those measurements can’t exist'}\n","get_passage result: {'score': 0.04490287974476814, 'start': 184, 'end': 217, 'answer': 'the vote has exposed polarization'}\n","get_passage result: {'score': 0.039290666580200195, 'start': 108, 'end': 149, 'answer': 'deep sense of purpose and positive impact'}\n","get_passage result: {'score': 0.0334671251475811, 'start': 470, 'end': 529, 'answer': 'a 60-year-old woman sitting alone in her car reading a book'}\n","get_passage result: {'score': 0.602963924407959, 'start': 383, 'end': 416, 'answer': \"Emperor Palpatine's granddaughter\"}\n","get_phrase result: {'score': 0.0006456131814047694, 'start': 1061, 'end': 1066, 'answer': 'Brown'}\n","get_passage result: {'score': 0.09158570319414139, 'start': 262, 'end': 291, 'answer': 'donate to the ALS Association'}\n","get_passage result: {'score': 0.01569715514779091, 'start': 617, 'end': 691, 'answer': 'to be proud of your genetic predisposition for good circulation and health'}\n","get_passage result: {'score': 0.08922947198152542, 'start': 340, 'end': 379, 'answer': 'everyone suddenly going dotty over them'}\n","get_passage result: {'score': 0.0003691531019285321, 'start': 1825, 'end': 1879, 'answer': 'four hours of power a day from the electricity company'}\n","get_passage result: {'score': 0.41050153970718384, 'start': 110, 'end': 148, 'answer': 'trees do relax their branches at night'}\n","get_passage result: {'score': 0.0006266325945034623, 'start': 254, 'end': 258, 'answer': 'Khan'}\n","get_phrase result: {'score': 1.0532835403864738e-05, 'start': 455, 'end': 468, 'answer': 'New York City'}\n","get_multi result: [{'score': 0.018898922950029373, 'start': 728, 'end': 782, 'answer': \"They've become a legend on their own, and out of reach\"}, {'score': 0.00875522755086422, 'start': 770, 'end': 782, 'answer': 'out of reach'}, {'score': 0.008468791842460632, 'start': 728, 'end': 764, 'answer': \"They've become a legend on their own\"}, {'score': 0.004191142972558737, 'start': 728, 'end': 751, 'answer': \"They've become a legend\"}, {'score': 0.0011833786265924573, 'start': 736, 'end': 782, 'answer': 'become a legend on their own, and out of reach'}]\n","get_passage result: {'score': 0.00832806620746851, 'start': 3887, 'end': 3900, 'answer': 'How I Learned'}\n","get_phrase result: {'score': 0.10710469633340836, 'start': 29, 'end': 59, 'answer': 'carried a young girl to safety'}\n","get_passage result: {'score': 0.17508883774280548, 'start': 289, 'end': 292, 'answer': 'tab'}\n","get_passage result: {'score': 2.767213572951732e-06, 'start': 819, 'end': 825, 'answer': 'drawer'}\n","get_passage result: {'score': 0.1030484214425087, 'start': 5261, 'end': 5285, 'answer': 'higher rates of violence'}\n","get_multi result: [{'score': 0.10509251058101654, 'start': 1311, 'end': 1324, 'answer': 'losing weight'}, {'score': 0.07935173064470291, 'start': 5125, 'end': 5158, 'answer': 'small health and aesthetic tweaks'}, {'score': 0.0661388486623764, 'start': 5131, 'end': 5158, 'answer': 'health and aesthetic tweaks'}, {'score': 0.06599364429712296, 'start': 1308, 'end': 1324, 'answer': 'by losing weight'}, {'score': 0.028589889407157898, 'start': 5115, 'end': 5158, 'answer': 'make some small health and aesthetic tweaks'}]\n","get_passage result: {'score': 0.3785756528377533, 'start': 369, 'end': 410, 'answer': 'Now that Trump has won the GOP nomination'}\n","get_passage result: {'score': 0.00028761630528606474, 'start': 418, 'end': 434, 'answer': 'Watermelon seeds'}\n","get_phrase result: {'score': 0.8556210398674011, 'start': 185, 'end': 197, 'answer': 'Ben Bernanke'}\n","get_phrase result: {'score': 0.14709995687007904, 'start': 222, 'end': 236, 'answer': 'Jordan Klepper'}\n","get_multi result: [{'score': 0.0007942852098494768, 'start': 2458, 'end': 2470, 'answer': '3 click step'}, {'score': 0.0001640242408029735, 'start': 2451, 'end': 2470, 'answer': 'simple 3 click step'}, {'score': 7.192200428107753e-05, 'start': 2458, 'end': 2535, 'answer': '3 click step recommended by SmarterWebLife to get yourself instant protection'}, {'score': 5.634028639178723e-05, 'start': 2447, 'end': 2470, 'answer': 'the simple 3 click step'}, {'score': 5.485500514623709e-05, 'start': 2458, 'end': 2465, 'answer': '3 click'}]\n","get_passage result: {'score': 0.006951472256332636, 'start': 41, 'end': 50, 'answer': 'marijuana'}\n","get_phrase result: {'score': 0.8874037861824036, 'start': 222, 'end': 229, 'answer': 'Feb. 24'}\n","get_passage result: {'score': 0.18800543248653412, 'start': 600, 'end': 621, 'answer': 'In very small amounts'}\n","get_phrase result: {'score': 0.025086594745516777, 'start': 1740, 'end': 1743, 'answer': '49%'}\n","get_passage result: {'score': 0.019932055845856667, 'start': 1026, 'end': 1039, 'answer': 'Neither had I'}\n","get_passage result: {'score': 0.08264447748661041, 'start': 2662, 'end': 2678, 'answer': 'inning-by-inning'}\n","get_passage result: {'score': 0.050749991089105606, 'start': 2195, 'end': 2264, 'answer': 'unless your car is safely parked, and out of the way of other traffic'}\n","get_phrase result: {'score': 0.17651022970676422, 'start': 409, 'end': 424, 'answer': 'a drink coaster'}\n","get_phrase result: {'score': 0.00015406598686240613, 'start': 423, 'end': 468, 'answer': '...and the gift isn’t always so well received'}\n","get_passage result: {'score': 0.6393395066261292, 'start': 348, 'end': 357, 'answer': 'Minnesota'}\n","get_phrase result: {'score': 0.14318008720874786, 'start': 407, 'end': 430, 'answer': 'Best Supporting Actress'}\n","get_passage result: {'score': 0.014518770389258862, 'start': 999, 'end': 1056, 'answer': 'every blue-eyed person alive today has this same mutation'}\n","get_phrase result: {'score': 0.02074972726404667, 'start': 0, 'end': 10, 'answer': 'Dawn Grace'}\n","get_passage result: {'score': 4.297984901313612e-07, 'start': 1132, 'end': 1141, 'answer': 'questions'}\n","get_passage result: {'score': 0.06011605262756348, 'start': 314, 'end': 356, 'answer': 'humor, sportsmanship and love of tradition'}\n","get_phrase result: {'score': 0.003147214651107788, 'start': 1323, 'end': 1334, 'answer': 'coconut oil'}\n","get_multi result: [{'score': 0.023834742605686188, 'start': 1397, 'end': 1421, 'answer': 'The higher they carry it'}, {'score': 0.01601988635957241, 'start': 1401, 'end': 1421, 'answer': 'higher they carry it'}, {'score': 0.011164737865328789, 'start': 1397, 'end': 1449, 'answer': 'The higher they carry it, the more content and happy'}, {'score': 0.007504080422222614, 'start': 1401, 'end': 1449, 'answer': 'higher they carry it, the more content and happy'}, {'score': 0.006780741270631552, 'start': 2070, 'end': 2112, 'answer': 'they like you and want to be where you are'}]\n","get_passage result: {'score': 4.78710580864572e-06, 'start': 390, 'end': 400, 'answer': 'spy camera'}\n","get_phrase result: {'score': 0.0762077197432518, 'start': 4551, 'end': 4566, 'answer': 'travel in style'}\n","get_phrase result: {'score': 0.09459181874990463, 'start': 14118, 'end': 14128, 'answer': 'Louisville'}\n","get_passage result: {'score': 0.46081507205963135, 'start': 1937, 'end': 1953, 'answer': 'racial profiling'}\n","get_passage result: {'score': 0.02780923806130886, 'start': 216, 'end': 258, 'answer': 'Men, however, just reach behind their neck'}\n","get_passage result: {'score': 0.13858306407928467, 'start': 215, 'end': 230, 'answer': 'Did you miss it'}\n","get_phrase result: {'score': 0.2642472982406616, 'start': 74, 'end': 85, 'answer': 'next spring'}\n","get_phrase result: {'score': 0.004392338916659355, 'start': 1688, 'end': 1718, 'answer': 'If there is nothing in the way'}\n","get_multi result: [{'score': 0.0005721849156543612, 'start': 1214, 'end': 1217, 'answer': '445'}, {'score': 0.0002934003423433751, 'start': 637, 'end': 639, 'answer': '16'}, {'score': 0.00025195590569637716, 'start': 1214, 'end': 1217, 'answer': '445'}, {'score': 0.00017032507457770407, 'start': 1214, 'end': 1247, 'answer': '445. Chandigarh, India: 25.93 446'}, {'score': 0.00013079338532406837, 'start': 1173, 'end': 1217, 'answer': 'Ukraine and Egypt. Here’s the bottom 20: 445'}]\n","get_passage result: {'score': 0.33174341917037964, 'start': 2958, 'end': 2963, 'answer': 'pizza'}\n","get_multi result: [{'score': 0.0001627778256079182, 'start': 1745, 'end': 1753, 'answer': 'Thailand'}, {'score': 4.984750194125809e-05, 'start': 616, 'end': 623, 'answer': 'Ecuador'}, {'score': 1.5152407286223024e-05, 'start': 3504, 'end': 3512, 'answer': 'Malaysia'}, {'score': 1.3768600183539093e-05, 'start': 584, 'end': 611, 'answer': 'eight international locales'}, {'score': 1.2870726095570717e-05, 'start': 3504, 'end': 3512, 'answer': 'Malaysia'}]\n","get_passage result: {'score': 0.05801840499043465, 'start': 3047, 'end': 3055, 'answer': 'bacteria'}\n","get_multi result: [{'score': 0.4410293996334076, 'start': 4240, 'end': 4255, 'answer': 'highly educated'}, {'score': 0.2667848467826843, 'start': 4240, 'end': 4255, 'answer': 'highly educated'}, {'score': 0.1694350391626358, 'start': 4223, 'end': 4255, 'answer': 'the new Beast is highly educated'}, {'score': 0.08968134224414825, 'start': 4231, 'end': 4255, 'answer': 'Beast is highly educated'}, {'score': 0.08763843029737473, 'start': 4223, 'end': 4255, 'answer': 'the new Beast is highly educated'}]\n","get_phrase result: {'score': 0.010165113024413586, 'start': 42, 'end': 56, 'answer': 'unmentionables'}\n","get_phrase result: {'score': 0.19231539964675903, 'start': 3784, 'end': 3789, 'answer': 'moral'}\n","get_multi result: [{'score': 0.36424562335014343, 'start': 3189, 'end': 3249, 'answer': 'it captured the exact spirit of what he was planning to make'}, {'score': 0.09656441956758499, 'start': 3181, 'end': 3249, 'answer': 'because it captured the exact spirit of what he was planning to make'}, {'score': 0.02459765039384365, 'start': 5482, 'end': 5530, 'answer': 'one of the best TV shows ever set in high school'}, {'score': 0.023772893473505974, 'start': 3192, 'end': 3249, 'answer': 'captured the exact spirit of what he was planning to make'}, {'score': 0.019147071987390518, 'start': 5447, 'end': 5452, 'answer': 'Buffy'}]\n","get_passage result: {'score': 0.03812824562191963, 'start': 130, 'end': 139, 'answer': 'Mr Burger'}\n","get_phrase result: {'score': 0.016416562721133232, 'start': 0, 'end': 8, 'answer': 'Hot dogs'}\n","get_phrase result: {'score': 0.013880409300327301, 'start': 1088, 'end': 1102, 'answer': 'Breaking Bad.\"'}\n","get_passage result: {'score': 0.002950267167761922, 'start': 504, 'end': 512, 'answer': 'A couple'}\n","get_phrase result: {'score': 6.167817628011107e-05, 'start': 708, 'end': 710, 'answer': '10'}\n","get_multi result: [{'score': 0.009420493617653847, 'start': 1431, 'end': 1434, 'answer': 'CEO'}, {'score': 0.008219495415687561, 'start': 1463, 'end': 1540, 'answer': 'Salesperson Surgeon Journalist Police officer Clergyperson Chef Civil servant'}, {'score': 0.007250711787492037, 'start': 1431, 'end': 1441, 'answer': 'CEO Lawyer'}, {'score': 0.006717240437865257, 'start': 1431, 'end': 1493, 'answer': 'CEO Lawyer Media (TV and radio) Salesperson Surgeon Journalist'}, {'score': 0.005998765584081411, 'start': 1431, 'end': 1482, 'answer': 'CEO Lawyer Media (TV and radio) Salesperson Surgeon'}]\n","get_passage result: {'score': 0.6167716383934021, 'start': 29, 'end': 54, 'answer': 'You may not even be aware'}\n","get_phrase result: {'score': 0.4115429222583771, 'start': 297, 'end': 302, 'answer': '1,080'}\n","get_phrase result: {'score': 0.600464940071106, 'start': 54, 'end': 60, 'answer': 'Google'}\n","get_multi result: [{'score': 0.00013976707123219967, 'start': 2365, 'end': 2389, 'answer': 'flakes or cayenne powder'}, {'score': 0.00010739979188656434, 'start': 2344, 'end': 2389, 'answer': 'fresh chilis, chilli flakes or cayenne powder'}, {'score': 0.00010239366383757442, 'start': 2358, 'end': 2389, 'answer': 'chilli flakes or cayenne powder'}, {'score': 9.81091070570983e-05, 'start': 2375, 'end': 2389, 'answer': 'cayenne powder'}, {'score': 7.912146247690544e-05, 'start': 2340, 'end': 2389, 'answer': 'Use fresh chilis, chilli flakes or cayenne powder'}]\n","get_phrase result: {'score': 0.5886784195899963, 'start': 60, 'end': 68, 'answer': 'Intrepid'}\n","get_phrase result: {'score': 0.010898297652602196, 'start': 158, 'end': 166, 'answer': 'MORNINGS'}\n","get_passage result: {'score': 9.84675352810882e-05, 'start': 2543, 'end': 2547, 'answer': 'UCLA'}\n","get_passage result: {'score': 0.06032063066959381, 'start': 6198, 'end': 6233, 'answer': 'people who think they’re doing good'}\n","get_passage result: {'score': 0.07114147394895554, 'start': 1096, 'end': 1102, 'answer': 'Pigeon'}\n","get_passage result: {'score': 0.001592056592926383, 'start': 255, 'end': 304, 'answer': \"you don't wanna f*ck w/ the Avengers of the Beach\"}\n","get_phrase result: {'score': 0.24598661065101624, 'start': 213, 'end': 224, 'answer': 'February 24'}\n","get_phrase result: {'score': 0.03597552701830864, 'start': 306, 'end': 334, 'answer': 'three hours of sleep a night'}\n","get_passage result: {'score': 0.1776566058397293, 'start': 585, 'end': 621, 'answer': 'By watching the trailer for \"G.B.F.\"'}\n","get_passage result: {'score': 0.001077834633179009, 'start': 69, 'end': 75, 'answer': 'Muncie'}\n","get_passage result: {'score': 0.636355459690094, 'start': 1762, 'end': 1767, 'answer': 'pussy'}\n","get_phrase result: {'score': 0.0007990688318386674, 'start': 491, 'end': 501, 'answer': 'Ryan said.'}\n","get_passage result: {'score': 0.20145706832408905, 'start': 747, 'end': 774, 'answer': 'new wars in the Middle East'}\n","get_phrase result: {'score': 0.26509949564933777, 'start': 175, 'end': 192, 'answer': 'Lawrence Phillips'}\n","get_phrase result: {'score': 0.008375605568289757, 'start': 70, 'end': 85, 'answer': 'Carrer Avinyó,'}\n","get_phrase result: {'score': 0.4954882860183716, 'start': 58, 'end': 70, 'answer': 'Nick Johnson'}\n","get_passage result: {'score': 0.017120251432061195, 'start': 550, 'end': 578, 'answer': 'a completely drained battery'}\n","get_passage result: {'score': 0.00836210884153843, 'start': 3782, 'end': 3846, 'answer': 'you’re not going to have single points of weakness on the system'}\n","get_passage result: {'score': 0.041248101741075516, 'start': 51, 'end': 74, 'answer': \"It's possible, but rare\"}\n","get_phrase result: {'score': 0.21768957376480103, 'start': 69, 'end': 80, 'answer': 'Colin Quinn'}\n","get_passage result: {'score': 0.2922798693180084, 'start': 9238, 'end': 9246, 'answer': 'chatbots'}\n","get_passage result: {'score': 0.00443948432803154, 'start': 272, 'end': 275, 'answer': 'mud'}\n","get_phrase result: {'score': 0.5294786691665649, 'start': 4176, 'end': 4182, 'answer': '$1,175'}\n","get_multi result: [{'score': 0.027060415595769882, 'start': 14661, 'end': 14672, 'answer': 'Lunch Boxes'}, {'score': 0.019851241260766983, 'start': 4577, 'end': 4589, 'answer': 'the internet'}, {'score': 0.008345740847289562, 'start': 3972, 'end': 4022, 'answer': 'when the majority of its pieces become little more'}, {'score': 0.006587108597159386, 'start': 15555, 'end': 15571, 'answer': 'lack of research'}, {'score': 0.006575829815119505, 'start': 3972, 'end': 4040, 'answer': 'when the majority of its pieces become little more than knick-knacks'}]\n","get_phrase result: {'score': 0.00914362259209156, 'start': 7, 'end': 78, 'answer': 'The evacuation of civilians and opposition fighters from eastern Aleppo'}\n","get_passage result: {'score': 0.007564899977296591, 'start': 1090, 'end': 1096, 'answer': 'farmer'}\n","get_phrase result: {'score': 0.00643039820715785, 'start': 181, 'end': 189, 'answer': 'The Jump'}\n","get_phrase result: {'score': 0.2439173460006714, 'start': 2341, 'end': 2351, 'answer': 'used a gun'}\n","get_phrase result: {'score': 0.16427432000637054, 'start': 1207, 'end': 1215, 'answer': 'Staubach'}\n","get_passage result: {'score': 0.010859251022338867, 'start': 1812, 'end': 1865, 'answer': 'Pokemon Sun and Moon will be translated into Mandarin'}\n","get_phrase result: {'score': 0.01702854037284851, 'start': 34, 'end': 50, 'answer': 'Whitney Thompson'}\n","get_passage result: {'score': 0.16321662068367004, 'start': 131, 'end': 169, 'answer': 'irreversible damage to the environment'}\n","get_multi result: [{'score': 0.03257814422249794, 'start': 186, 'end': 207, 'answer': 'purely coincidental.\"'}, {'score': 0.024073120206594467, 'start': 186, 'end': 205, 'answer': 'purely coincidental'}, {'score': 0.013147435151040554, 'start': 193, 'end': 207, 'answer': 'coincidental.\"'}, {'score': 0.009715094231069088, 'start': 193, 'end': 205, 'answer': 'coincidental'}, {'score': 0.008230241015553474, 'start': 183, 'end': 207, 'answer': 'is purely coincidental.\"'}]\n","get_passage result: {'score': 0.07735922187566757, 'start': 1919, 'end': 1979, 'answer': 'It could represent the danger of a snake or another predator'}\n","get_passage result: {'score': 0.5302248597145081, 'start': 1308, 'end': 1313, 'answer': 'water'}\n","get_phrase result: {'score': 0.23396387696266174, 'start': 245, 'end': 261, 'answer': 'at his very best'}\n","get_passage result: {'score': 0.002435428788885474, 'start': 194, 'end': 205, 'answer': 'Mexican man'}\n","get_phrase result: {'score': 0.269248366355896, 'start': 1453, 'end': 1457, 'answer': 'rags'}\n","get_phrase result: {'score': 0.0003124266513623297, 'start': 442, 'end': 486, 'answer': 'Police officers are here to protect citizens'}\n","get_phrase result: {'score': 0.0018016169779002666, 'start': 120, 'end': 127, 'answer': 'Houston'}\n","get_passage result: {'score': 0.0009223720408044755, 'start': 787, 'end': 793, 'answer': 'Alison'}\n","get_passage result: {'score': 0.003418802050873637, 'start': 1164, 'end': 1182, 'answer': 'just pay with cash'}\n","get_phrase result: {'score': 0.010062885470688343, 'start': 1261, 'end': 1269, 'answer': 'Vogue UK'}\n","get_passage result: {'score': 0.13920988142490387, 'start': 574, 'end': 631, 'answer': 'there is nothing to worry about from a health perspective'}\n","get_passage result: {'score': 0.03091602399945259, 'start': 892, 'end': 912, 'answer': 'Trump wasn’t on coke'}\n","get_phrase result: {'score': 0.02478519082069397, 'start': 278, 'end': 314, 'answer': 'coconut oil with a pinch of turmeric'}\n","get_passage result: {'score': 0.06011461839079857, 'start': 476, 'end': 536, 'answer': 'It’s chock-full of nutrients and electrolytes like potassium'}\n","get_passage result: {'score': 0.02629792131483555, 'start': 1167, 'end': 1172, 'answer': 'Megan'}\n","get_phrase result: {'score': 0.7184184193611145, 'start': 22, 'end': 35, 'answer': 'Chris Crocker'}\n","get_passage result: {'score': 0.0002003192057600245, 'start': 2455, 'end': 2471, 'answer': 'Talk to a doctor'}\n","get_passage result: {'score': 0.0044166226871311665, 'start': 443, 'end': 505, 'answer': 'motorcycle gloves, next to a colorful, shiny motorcycle helmet'}\n","get_phrase result: {'score': 0.08030755817890167, 'start': 457, 'end': 496, 'answer': 'A number 7 with medium fries and a Coke'}\n","get_phrase result: {'score': 0.010040407069027424, 'start': 0, 'end': 9, 'answer': 'Minnesota'}\n","get_passage result: {'score': 0.010756399482488632, 'start': 621, 'end': 654, 'answer': 'TURN AROUND and exit the building'}\n","get_passage result: {'score': 0.005468327552080154, 'start': 644, 'end': 682, 'answer': \"Now that the game's out in our country\"}\n","get_passage result: {'score': 0.0017711524851620197, 'start': 46, 'end': 91, 'answer': 'hugged her, and ended up stealing her jewelry'}\n","get_phrase result: {'score': 0.8992927670478821, 'start': 441, 'end': 454, 'answer': 'Cecily Strong'}\n","get_multi result: [{'score': 4.1129052988253534e-05, 'start': 1709, 'end': 1711, 'answer': '19'}, {'score': 6.593574653379619e-06, 'start': 1425, 'end': 1432, 'answer': 'routine'}, {'score': 3.4999893614440225e-06, 'start': 1421, 'end': 1432, 'answer': 'any routine'}, {'score': 2.523583589209011e-06, 'start': 1582, 'end': 1584, 'answer': '18'}, {'score': 1.695711944194045e-06, 'start': 1709, 'end': 1751, 'answer': '19. Basically, you like the best of things'}]\n","get_phrase result: {'score': 6.277908687479794e-05, 'start': 2804, 'end': 2808, 'answer': 'Barr'}\n","get_passage result: {'score': 0.3567162752151489, 'start': 312, 'end': 325, 'answer': 'airline greed'}\n","get_passage result: {'score': 0.0961788073182106, 'start': 194, 'end': 213, 'answer': 'Springfield, Oregon'}\n","get_phrase result: {'score': 0.0045626601204276085, 'start': 1524, 'end': 1535, 'answer': 'amazing dog'}\n","get_passage result: {'score': 2.129090717062354e-06, 'start': 405, 'end': 418, 'answer': 'PlayStation 4'}\n","get_passage result: {'score': 3.806424865615554e-05, 'start': 182, 'end': 216, 'answer': 'Batman was able to weaken Superman'}\n","get_passage result: {'score': 0.11415938287973404, 'start': 384, 'end': 420, 'answer': 'post-micturition convulsion syndrome'}\n","get_passage result: {'score': 1.9247187083237804e-05, 'start': 38, 'end': 98, 'answer': 'NASA has just confirmed that a gargantuan mile-long asteroid'}\n","get_phrase result: {'score': 0.6053978204727173, 'start': 1249, 'end': 1291, 'answer': '\"Where do you see yourself in five years?\"'}\n","get_passage result: {'score': 0.1662052869796753, 'start': 263, 'end': 316, 'answer': '\"Dumb British blond fucks 15 million people at once.\"'}\n","get_phrase result: {'score': 0.022947844117879868, 'start': 228, 'end': 237, 'answer': 'Patterson'}\n","get_passage result: {'score': 0.052529845386743546, 'start': 297, 'end': 309, 'answer': 'bullshitting'}\n","get_phrase result: {'score': 0.02437904290854931, 'start': 702, 'end': 711, 'answer': 'diversity'}\n","get_multi result: [{'score': 0.07372209429740906, 'start': 0, 'end': 7, 'answer': 'Florida'}, {'score': 0.004782426171004772, 'start': 0, 'end': 63, 'answer': 'Florida may be just the fourth most populous state in the U.S.,'}, {'score': 0.0017929637106135488, 'start': 0, 'end': 50, 'answer': 'Florida may be just the fourth most populous state'}, {'score': 0.0011994056403636932, 'start': 0, 'end': 61, 'answer': 'Florida may be just the fourth most populous state in the U.S'}, {'score': 0.0011275712167844176, 'start': 175, 'end': 185, 'answer': 'California'}]\n","get_phrase result: {'score': 0.2225462943315506, 'start': 295, 'end': 329, 'answer': \"Hagrid couldn't produce a Patronus\"}\n","get_phrase result: {'score': 0.02934516780078411, 'start': 56, 'end': 77, 'answer': 'Democrat Jason Kander'}\n","get_passage result: {'score': 0.09216741472482681, 'start': 6186, 'end': 6197, 'answer': '5.4 minutes'}\n","get_passage result: {'score': 0.02077646367251873, 'start': 1080, 'end': 1092, 'answer': \"there's Rudy\"}\n","get_passage result: {'score': 0.006483148783445358, 'start': 3905, 'end': 3941, 'answer': 'how well they bound to their antigen'}\n","get_multi result: [{'score': 0.0012357725063338876, 'start': 1846, 'end': 1861, 'answer': 'portable toilet'}, {'score': 0.000754264765419066, 'start': 1855, 'end': 1861, 'answer': 'toilet'}, {'score': 0.0003382248687557876, 'start': 3501, 'end': 3506, 'answer': 'Spain'}, {'score': 0.00023985773441381752, 'start': 3491, 'end': 3506, 'answer': 'Nowhere – Spain'}, {'score': 0.00015176396118476987, 'start': 1841, 'end': 1861, 'answer': 'this portable toilet'}]\n","get_phrase result: {'score': 0.007832081988453865, 'start': 483, 'end': 495, 'answer': 'white pepper'}\n","get_passage result: {'score': 0.17969739437103271, 'start': 2511, 'end': 2533, 'answer': 'prostate and anal play'}\n","get_passage result: {'score': 0.04956374689936638, 'start': 330, 'end': 403, 'answer': 'their strange dating preferences, to some questionable business practices'}\n","get_multi result: [{'score': 0.0006135979201644659, 'start': 4426, 'end': 4456, 'answer': 'evolves into some coconut tree'}, {'score': 0.0002955815871246159, 'start': 4444, 'end': 4456, 'answer': 'coconut tree'}, {'score': 0.00017492831102572381, 'start': 524, 'end': 530, 'answer': 'Klefki'}, {'score': 0.00012780573160853237, 'start': 4423, 'end': 4456, 'answer': 'it evolves into some coconut tree'}, {'score': 9.747153671924025e-05, 'start': 4418, 'end': 4456, 'answer': 'then it evolves into some coconut tree'}]\n","get_multi result: [{'score': 0.3924480676651001, 'start': 2450, 'end': 2485, 'answer': 'there are plenty of fish in the sea'}, {'score': 0.0860167145729065, 'start': 3618, 'end': 3689, 'answer': 'Pour yourself a drink, put on some lipstick, and pull yourself together'}, {'score': 0.06084278225898743, 'start': 2450, 'end': 2485, 'answer': 'there are plenty of fish in the sea'}, {'score': 0.034009724855422974, 'start': 2460, 'end': 2485, 'answer': 'plenty of fish in the sea'}, {'score': 0.033392928540706635, 'start': 3667, 'end': 3691, 'answer': 'pull yourself together.\"'}]\n","get_phrase result: {'score': 0.0001268660998903215, 'start': 410, 'end': 433, 'answer': 'That’s not Donald Trump'}\n","get_multi result: [{'score': 0.3057910203933716, 'start': 646, 'end': 654, 'answer': 'Dan Bell'}, {'score': 0.031007397919893265, 'start': 1088, 'end': 1091, 'answer': 'Dan'}, {'score': 0.024337952956557274, 'start': 3521, 'end': 3524, 'answer': 'Dan'}, {'score': 0.023270392790436745, 'start': 2249, 'end': 2253, 'answer': 'Tony'}, {'score': 0.007662809919565916, 'start': 3521, 'end': 3524, 'answer': 'Dan'}]\n","get_passage result: {'score': 0.2444303333759308, 'start': 4709, 'end': 4745, 'answer': 'the transition to the service sector'}\n","get_passage result: {'score': 0.4661473035812378, 'start': 191, 'end': 212, 'answer': 'chewed on some plants'}\n","get_passage result: {'score': 0.021767107769846916, 'start': 521, 'end': 547, 'answer': 'refusing to accept the tip'}\n","get_phrase result: {'score': 0.011482995934784412, 'start': 192, 'end': 210, 'answer': 'Christopher Suprun'}\n","get_multi result: [{'score': 0.16281570494174957, 'start': 2880, 'end': 2894, 'answer': 'Rachel Crawley'}, {'score': 0.1285201460123062, 'start': 323, 'end': 337, 'answer': 'Rachel Crawley'}, {'score': 0.06888961791992188, 'start': 5774, 'end': 5788, 'answer': 'Rachel Crawley'}, {'score': 0.02446325495839119, 'start': 5882, 'end': 5887, 'answer': 'vegan'}, {'score': 0.018614277243614197, 'start': 3967, 'end': 3981, 'answer': 'Rachel Crawley'}]\n","get_passage result: {'score': 0.002511553233489394, 'start': 161, 'end': 165, 'answer': 'dead'}\n","get_phrase result: {'score': 0.7423131465911865, 'start': 0, 'end': 14, 'answer': 'Richard Belzer'}\n"]}]},{"cell_type":"code","source":["\n","\n","# Convert JSONL to CSV\n","def jsonl_to_csv(jsonl_file, csv_file):\n","    with open(jsonl_file, 'r') as infile:\n","        data = [json.loads(line) for line in infile]\n","\n","    df = pd.DataFrame(data)\n","    df['spoiler'] = df['spoiler'].apply(lambda x: ' '.join(x) if x else '')\n","\n","    # Save to CSV with proper quoting\n","    df.to_csv(csv_file, index=False, quoting=csv.QUOTE_ALL)\n","\n","# Convert the output JSONL file to CSV\n","jsonl_file = '/content/drive/MyDrive/task-2/data/prediction_task2.jsonl'\n","csv_file = '/content/drive/MyDrive/task-2/data/prediction_task2.csv'\n","jsonl_to_csv(jsonl_file, csv_file)\n"],"metadata":{"id":"FJtmkoYnYzVz","executionInfo":{"status":"error","timestamp":1720913445747,"user_tz":240,"elapsed":313,"user":{"displayName":"MMA Construction","userId":"18335187591541982093"}},"outputId":"59b1830e-0ae2-4d8f-b5bf-b9ea8aef57a9","colab":{"base_uri":"https://localhost:8080/","height":297}},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/task-2/data/prediction_task2.jsonl'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fbb18dced83e>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mjsonl_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/task-2/data/prediction_task2.jsonl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/task-2/data/prediction_task2.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mjsonl_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonl_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-fbb18dced83e>\u001b[0m in \u001b[0;36mjsonl_to_csv\u001b[0;34m(jsonl_file, csv_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert JSONL to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjsonl_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonl_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonl_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/task-2/data/prediction_task2.jsonl'"]}]}]}